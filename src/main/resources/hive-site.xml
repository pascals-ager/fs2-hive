<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>hive.txn.manager</name>
        <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
        <description>
            Set to org.apache.hadoop.hive.ql.lockmgr.DbTxnManager as part of turning on Hive
            transactions, which also requires appropriate settings for hive.compactor.initiator.on,
            hive.compactor.worker.threads, hive.support.concurrency (true),
            and hive.exec.dynamic.partition.mode (nonstrict).
            The default DummyTxnManager replicates pre-Hive-0.13 behavior and provides
            no transactions.
        </description>
    </property>
    <property>
        <name>hive.support.concurrency</name>
        <value>true</value>
        <description>
            Whether Hive supports concurrency control or not.
            A ZooKeeper instance must be up and running when using zookeeper Hive lock manager
        </description>
    </property>


    <property>
        <name>hive.compactor.initiator.on</name>
        <value>true</value>
        <description>
            Whether to run the initiator and cleaner threads on this metastore instance or not.
            Set this to true on one instance of the Thrift metastore service as part of turning
            on Hive transactions. For a complete list of parameters required for turning on
            transactions, see hive.txn.manager.
        </description>
    </property>


    <property>
        <name>hive.compactor.worker.threads</name>
        <value>10</value>
        <description>
            How many compactor worker threads to run on this metastore instance. Set this to a
            positive number on one or more instances of the Thrift metastore service as part of
            turning on Hive transactions. For a complete list of parameters required for turning
            on transactions, see hive.txn.manager.
            Worker threads spawn MapReduce jobs to do compactions. They do not do the compactions
            themselves. Increasing the number of worker threads will decrease the time it takes
            tables or partitions to be compacted once they are determined to need compaction.
            It will also increase the background load on the Hadoop cluster as more MapReduce jobs
            will be running in the background.
        </description>
    </property>


    <property>
        <name>hive.exec.dynamic.partition.mode</name>
        <value>nonstrict</value>
    </property>

    <property>
        <name>hive.exec.dynamic.partition</name>
        <value>true</value>
    </property>

    <property>
        <name>hive.optimize.sort.dynamic.partition</name>
        <value>true</value>
    </property>


    <property>
        <name>hive.exec.compress.intermediate</name>
        <value>true</value>
    </property>

    <property>
        <name>hive.exec.compress.output</name>
        <value>true</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://postgresql-metastore-two/default</value>
        <description>
            JDBC connection string for the data store which contains metadata.
        </description>
    </property>


    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
        <description>
            JDBC Driver class name for the data store which contains metadata.
        </description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
        <description>
            User name for connecting to PostgreSQL server.
        </description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
        <description>
            Password for connecting to PostgreSQL server.
        </description>
    </property>

    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://hive-metastore-two:9083</value>
        <description>
            Hive connects to one of these URIs to make metadata requests to a remote Metastore (comma separated list of
            URIs).
        </description>
    </property>


    <property>
        <name>hive.users.in.admin.role</name>
        <value>root,hive,yarn,nifi</value>
    </property>


    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
    </property>

    <property>
        <name>hive.server2.enable.doAs</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.metastore.sasl.enabled</name>
        <value>false</value>
        <description>If true, the metastore Thrift interface will be secured with SASL. Clients must authenticate with
            Kerberos.
        </description>
    </property>
    <property>
        <name>hive.server2.authentication</name>
        <value>NONE</value>
    </property>
    <property>
        <name>fs.hdfs.impl.disable.cache</name>
        <value>true</value>
    </property>
    <property>
        <name>fs.file.impl.disable.cache</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
    </property>


</configuration>
